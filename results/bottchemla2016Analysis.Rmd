---
title: Scripts to analyse a replication of Bott and Chemla 2016.
author: "bsparkes"
date: "24th May 2018"
output:
  html_document: default
  pdf_document: default
---

# Packages

Let's load of few packages which will help us go through the data.
```{r}
library(tidyverse)
library(lme4)
library(languageR)
library(plyr) # for figuring out percentages
# library(quantmod)
library(dplyr)
library(sjPlot)
library(sjmisc)
library(memisc)
```

# Preliminaries

## Setting the current directory

For whatever reason, RStidio has troubles with figuring out where stuff is.
The following commands set the current file path as the working directory.

```{r}
# currentDir = dirname(rstudioapi::getActiveDocumentContext()$path)
# setwd(currentDir)
# getwd()
```

## Loading the data

First, let's load up the CSV
```{r}
p = read.csv("../data/bottchemla2016.csv", quote = "\"")
# pOrig = p
summary(p)
# head(p)
```

## Reformatting the data

In our analysis we'll want to get the percentage of 'better' as a responsepercentage of 'better' as a response.
One way to do this is to use the fact that 'responseChoice' returns 1 if 'better' was chosen, and 0 otherwise.
For, then the percentage of 'better' responses will be the sum of the response vector, divided by the length of the response vector.
In pseudo code: responsePercent = sum(responses)/length(responses).
There's a slight snag, as the data we get from mturk isn't in quite the right format for this operation.
In short, responses are marked "1" and "0", respectively, as opposed to 1 and 0.
While the primary case of interest is response choices, this issues holds for each type of response, and can be seen by uncommenting the following lines.

```{r}
# p$responseChoice
# p$pOChoice
# p$pTChoice
```

To solve this problem, we use the 'revalue' function to substitute the factors with quotation marks for factors without.
This will then allow us to use the 'as.integer' and 'as.character' functions to read off the data as integers.

```{r}
p$responseChoice = revalue(p$responseChoice, c("\"0\""="0", "\"1\""="1"))
p$pOChoice = revalue(p$pOChoice, c("\"0\""="0", "\"1\""="1"))
p$pTChoice = revalue(p$pTChoice, c("\"0\""="0", "\"1\""="1"))

# Well, this didn't help the sum contrast problemâ€¦
p$primeStrengthText = revalue(p$primeStrengthText, c('\"strong\"'="verystrong", '\"weak\"'="awfullyweak"))
```

We can check the revaluing worked by running the following lines.

```{r}
# p$responseChoice
# p$pOChoice
# p$pTChoice
```

And, the percentage of 'strong' responses can now be obtained by running the following code.

```{r}
sum(as.integer(as.character(p$responseChoice)))/length(p$responseChoice)
```

## Refining the data

First, we'll remove those participatns who did not declare English as their native language.
We also exclude those who did not delcare a native langauge.
One might reasonably assume that those who did not delcare a language spoke English, as all participatns of the HIT had to be located in the US.
However, as only two participants did not enter a language, this is only a minor impoverishment of our trial data, and with what is intuitively an imporvement to our data as a whole.
There were a number of participants who delcared more than one language (including English), and as the prompt in the experiment asked for native language (more or less explicitly) we kept these data from these participants.

```{r}
summary(p$language)
table(p$language)
p = subset(p, language!='""' & language!='"Chinese"' & language!='"Russian"' & language!='"Urdu"' & language!='"spanish"') #& language!='"English, Chinese"' & language!='"english and vietnamese"')
# summary(lp$language)
# length(p$workerid)
# summary(p)
```

Second, there's also good reason to remove participants who answered the questions /far/ too quickly.
It's arguable where the line should be drawn, but less than three minutes certainly seems to fast, as going through the experiment as fast as possible (using the keyboard, not reading the sentnces, etc.) takes around 40 seconds.
Further, if we restict to three minutes this amounts to roughly one and a half a seconds per trial, which seems a reasonable lower bound.

We have a similar problem to before, in that the time of the experiment is recorded as a string.
Further, here we cannot easily use the revalue function, as there are simply too many different values to consider, and these would change on each run of the experiment.
So, we use the 'gsub' function, to replace each of the problematic quotation marks, which will allow us then to treat the string as a number using the 'as.numeric' and 'as.character' functions.
A roundabout, but working solution.

```{r}
# table(p$Answer.time_in_minutes)
p$Answer.time_in_minutes <- gsub("\"", "", p$Answer.time_in_minutes)
p$Answer.time_in_minutes <- as.numeric(as.character(p$Answer.time_in_minutes))
mean(p$Answer.time_in_minutes)
p = subset(p, Answer.time_in_minutes >= 3)
# table(p$Answer.time_in_minutes)

```


Our dataset contains a lot of information, and before proceeding there are two operations which we'll perform.
First, we'll exclude filler trails, which will allow for more straightforward analysis code.
Second, we'll exclude trains in which the respondents did not choose the 'correct' primes, in line with Bott and Chemla.

The following table will be useful to keep in mind as it shows that raw counts of trails relative to prime and response type.

```{r}
table(p$responseTypeText, p$primeTypeText)
```

So, let's filter out the filler trials from the CSV
First, we can check how many fillers we have.

```{r}
table(p$trial_type)
```

Second, we filter the CSV using the subset operation.

```{r}
rp = subset(p, trial_type=='"response"')
```

Finally, we can check we've done the right thing.

```{r}
table(rp$trial_type)
```

Next, we can now filter the CSV so that we only have entries for correct prime responses.

First, we see how many correct/incorrect prime responses there were.

```{r}
table(rp$correctPChoices)
```

Second, filter using the fact that we had the foresight to log whether the respondant chose the correct primes.

```{r}
rp = subset(rp, correctPChoices=='true')
```
And again, we can check we've done the right thing
```{r}
table(rp$correctPChoices)
```

We can now have a peak at how the strength of primes influences the responses of participants.

```{r}
table(rp$primeStrengthText, rp$responseChoiceText)
```

We can now look at the raw counts of prime and reponse types again, if we like.

```{r}
table(p$responseTypeText, p$primeTypeText)
table(rp$responseTypeText, rp$primeTypeText)
```





## Further Subsets of data

There are two important subsets of the data we'll be interested in analysing.
The first is within category priming, and the second is between category priming.
In the following two subsections we create two distinct datasets from the original data.
We won't actually use these in creating models, but they can be useful to look at the details.

### Within category priming dataset

For the within category priming dataset we need to ensure that the prime category and the response category are the same.
So, we use the 'subset' function to exclude the results for which the prime category differs from the response category, using the fact that we've logged the relation between primes and response.
```{r}
table(rp$withBet)
wrp = subset(rp, WithBet=='"within"')
```
We can look at the refined dataset, if we wish, by uncommeting the following code.
```{r}
# summary(wrp)
```
We can also check that we've got the right restrictions, we're aiming for the diagonal (ignoring fillers categories)
```{r}
table(wrp$responseTypeText, wrp$primeTypeText)
```

### Between category priming dataset

As in the case of within category priming, we use the fact that we've logged the relation between primes and responses to exclude cases in which the prime and response category differs.
```{r}
brp = subset(rp, WithBet=='"between"')
```
As before, we can check that we've got the right restrictions.
```{r}
table(brp$responseTypeText, brp$primeTypeText)
```

We're now ready to create a model!

# Modelling

## The broad dataset
First, let's look at the dataset where the only operation we've performed is removing fillers, and trails for which the participant did not choose the correct responses for the primes they saw.
Follow Bott and Chemla, we'll be using a logit mixed-effect model, so 'gmler' does the trick.
However, we need to set the right contrasts first.

```{r}

contrasts(rp$WithBet)
contrasts(rp$primeStrengthText)
contrasts(rp$primeStrengthText) <- contr("sum", base=2)
contrasts(rp$WithBet) <- contr("sum", base=1)
contrasts(rp$WithBet)
contrasts(rp$primeStrengthText)

rp.model = glmer(responseChoice ~ primeStrengthText*WithBet + (1 + primeStrengthText*WithBet | workerid), data=rp , family="binomial")
```
Success! So let's look at a summary.


```{r}
summary(rp.model)
```

## Ugh

Bott and Chemla include a model with the same structure, but with a change of contrasts for the within/between factor to investigate simple effects.
First the slope for between.

```{r}
rpS <- rp
contrasts(rpS$WithBet)
contrasts(rpS$primeStrengthText)
contrasts(rpS$primeStrengthText) <- contr("sum", base=2)
contrasts(rpS$WithBet) <- contr("treatment", base=1)
contrasts(rpS$WithBet)
contrasts(rpS$primeStrengthText)

rp.simpleModel <- glmer(responseChoice ~ primeStrengthText*WithBet + (1 + primeStrengthText*WithBet | workerid), data=rpS, family="binomial")
summary(rp.simpleModel)
```

And now the slope for within.

```{r}
rpS2 <- rp
contrasts(rpS2$WithBet)
contrasts(rpS2$primeStrengthText)
contrasts(rpS2$primeStrengthText) <- contr("sum", base=2)
contrasts(rpS2$WithBet) <- contr("treatment", base=2)
contrasts(rpS2$WithBet)
contrasts(rpS2$primeStrengthText)

rp.simpleModel2 <- glmer(responseChoice ~ primeStrengthText*WithBet + (1 + primeStrengthText*WithBet | workerid), data=rpS2, family="binomial")
summary(rp.simpleModel2)
```


```{r}
# sjp.setTheme(theme = "forest")
# sjp.glmer(rp.model,
#           facet.grid = FALSE,
#           sort = "sort.all")
```


## Within detail

Now let's take a look at the case of within category priming.
The parameters we use follow those of Bott and Chemla, and we can first look at their effect of the main dataset.
```{r}
# rp.modelWithin = glmer(responseChoice ~ primeStrength * WithCat +  (1 + primeStrength * WithCat | workerid), data=rp, family = binomial(link = "logit"))
# summary(rp.modelWithin)
```

Of course, our interest is in a restriction of the main dataset so that we only cosnider within category reponses.

```{r}
# contrasts(wrp$WithCat)
contrasts(wrp$primeStrengthText)
contrasts(wrp$WithCat) <- contr.treatment(4)
contrasts(wrp$primeStrengthText) <- contr("sum", base=2)
# contrasts(wrp$WithCat)
wrp.modelWithin = glmer(responseChoice ~ primeStrengthText * WithCat +  (1 + primeStrengthText * WithCat | workerid), data=wrp, family = binomial(link = "logit"))
summary(wrp.modelWithin)
```



##  Between detail

We repeat the steps for the within category model.
First, the model with respect to the rp dataset.

```{r}
# rp.modelBetween = glmer(responseChoice ~ primeStrength * BetCat  +  (1 + primeStrength * BetCat | workerid), data=rp, family = binomial(link = "logit"))
# summary(rp.modelBetween)
```

And then with respect to the restriction of the rp dataset which only includes responses from the same category as the prime.

```{r}
contrasts(brp$BetCat)
contrasts(brp$primeStrengthText)
contrasts(brp$BetCat) <- contr("treatment")
contrasts(brp$primeStrengthText) <- contr("sum", base=2)
# contrasts(brp$BetCat)
# contrasts(brp$responseChoice)
brp.modelBetween = glmer(responseChoice ~ primeStrengthText * BetCat  +  (1 + primeStrengthText * BetCat | workerid), data=brp, family = binomial(link = "logit"))
summary(brp.modelBetween)
```

# Visualising the data (kind of)

First we set the theme.
```{r}
theme_set(theme_bw())
```

Now, let's construct percentages of 'better' responses for each prime and response category pairing.
Recall, responseChoice returns 0 for a weak selection, and 1 for a selection of 'better', which Bott and Chemla take to indicate the desire for a pragmatically enriched 'strong' card.
What we're going to want is the percentage for each individual, and from this we'll be able to extract the mean, standard deviation, and so onâ€¦
How exactly to do this took a little working.

First, we create a new frame using the 'aggregate' function, which sums the responseChoice, but keeps these separate according to the workerid and primeType.
Then, we reshape the dataframe so that we've got weak primes and strong primes by worker.
Then, we do a little renaming to make things clear.
After this is done, we can go and calculate the mean, standard error, and adjusted mean, etc.
It's all quite tedious, but â€¦ at least we now have everything that we need for a plot.
At least, in terms of how to figure it out, the thing is that this doesn't take the category of the prime and response into account, which would've been nice.

```{r}
# table(rp$workerid, rp$responseChoice)
exl <- aggregate(as.numeric(as.character(rp$responseChoice)), list(rp$workerid, rp$primeStrength), sum)
exl <- reshape(exl, timevar="Group.2", idvar="Group.1", direction="wide")

colnames(exl)[colnames(exl) =="Group.1"] <- "workerid"
colnames(exl)[colnames(exl) =="x.0"] <- "weakPrimeSum"
colnames(exl)[colnames(exl) =="x.1"] <- "strongPrimeSum"
head(exl)

exl$weakPercentage <- exl$weakPrimeSum/16
exl$strongPercentage <- exl$strongPrimeSum/16
exl$responseTotal <- (exl$weakPrimeSum + exl$strongPrimeSum)
exl$responsePercentage <- (exl$weakPercentage + exl$strongPercentage)/2

exlWeakMean <- mean(exl$weakPrimeSum)
exlStrongMean <- mean(exl$strongPrimeSum)

exlWeakSD <- sd(exl$weakPrimeSum)
exlStrongSD <- sd(exl$strongPrimeSum)

exlWeakSE <- exlWeakSD/sqrt(length(exl$workerid))
exlStrongSE <- exlStrongSD/sqrt(length(exl$workerid))

exlWeakMeanWiSE <- (exlWeakMean + exlWeakSE)
exlWeakMeanWoSE <-(exlWeakMean - exlWeakSE)

exlWeakMeanP <- exlWeakMean/16
exlWeakMeanWiSEP <- exlWeakMeanWiSE/16
exlWeakMeanWoSEP <- exlWeakMeanWoSE/16


exlStrongMeanWiSE <- (exlStrongMean + exlStrongSE)
exlStrongMeanWoSE <-(exlStrongMean - exlStrongSE)

exlStrongMeanP <- exlStrongMean/16
exlStrongMeanWiSEP <- exlStrongMeanWiSE/16
exlStrongMeanWoSEP <- exlStrongMeanWoSE/16

exlWeakMeanP
exlWeakMeanWiSEP
exlWeakMeanWoSEP
exlStrongMeanP
exlStrongMeanWiSEP
exlStrongMeanWoSEP
```

Ok, so we're going to try and do this by category.
First, we'll use 'aggregate' to pick up the relevant columns and their sum.
We include workerid here because we want to be precise.
The consideration of precision comes in when we want to calculate the standard error, as here we need the number of samples.
But, as we've excluded some of the data, it's quite possible that the number of samples for a prime-category pairing is going to be fewer than desired, as a particular participant to the experiment may have failed to respond correctly to the prime.
So, once we've done this we'll make a new coloumn to capture the prime-category pair, and then we'll make a new dataframe with the workerid, prime-category pair, and the raw count of the strong responses given the prime-category pair.
We then rename the columns to make things a little easier to deal with.
Now, the task is to get the appropriate counts for each prime-category pair.
There are two things we need to do.
For, to do standard arithmetic operations we need to remove the NAs.
But, we also want to make a count of these for each prime-category to make sure that we get the right mean, sd, etc
So, here we use the 'is.na' function with 'sum' and the rest.
It's rather laborious, but the results look to be soundâ€¦

â€¦ or it was, but something seems to have happened when I was figuring out how to be sure of the bases in the models above to break this.
I don't really care to fix the code, as the results have already been recorded in the LaTex write-up.

```{r}
exlx <- aggregate(as.numeric(as.character(rp$responseChoice)), list(rp$workerid, rp$primeStrengthText, rp$BetCat), sum)

exly <- aggregate(as.numeric(as.character(rp$correctPChoices)), list(rp$workerid, rp$primeStrengthText, rp$BetCat), length)

colnames(exlx)[colnames(exlx) =="Group.1"] <- "workerid"
colnames(exlx)[colnames(exlx) =="Group.2"] <- "primeStrength"
colnames(exlx)[colnames(exlx) =="Group.3"] <- "categories"
colnames(exlx)[colnames(exlx) =="x"] <- "rawCount"
exlx$compact <- paste(exlx$primeStrength, exlx$categories, sep="")

colnames(exly)[colnames(exly) =="Group.1"] <- "workerid"
colnames(exly)[colnames(exly) =="Group.2"] <- "primeStrength"
colnames(exly)[colnames(exly) =="Group.3"] <- "categories"
colnames(exly)[colnames(exly) =="x"] <- "rawSamples"
exly$compact <- paste(exlx$primeStrength, exlx$categories, sep="")

dd <- data.frame(exlx$workerid, exlx$compact,  exlx$rawCount)
dd <- reshape(dd, timevar="exlx.compact", idvar="exlx.workerid", direction="wide")

de <- data.frame(exly$workerid, exly$compact,  exly$rawSamples)
de <- reshape(de, timevar="exly.compact", idvar="exly.workerid", direction="wide")

colnames(dd)[colnames(dd) =="exlx.workerid"]  <- "workerid"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"strong\"\"NUM4NUM4\""] <- "strongNUM4NUM4"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"weak\"\"NUM4NUM4\""] <- "weakNUM4NUM4"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"strong\"\"NUM4SOME\""] <- "strongNUM4SOME"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"weak\"\"NUM4SOME\""] <- "weakNUM4SOME"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"strong\"\"SOMENUM4\""] <- "strongSOMENUM4"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"weak\"\"SOMENUM4\""] <- "weakSOMENUM4"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"strong\"\"SOMESOME\""] <- "strongSOMESOME"
colnames(dd)[colnames(dd) =="exlx.rawCount.\"weak\"\"SOMESOME\""] <- "weakSOMESOME"

colnames(de)[colnames(de) =="exly.workerid"]  <- "workerid"
colnames(de)[colnames(de) =="exly.rawSamples.\"strong\"\"NUM4NUM4\""] <- "strongNUM4NUM4"
colnames(de)[colnames(de) =="exly.rawSamples.\"weak\"\"NUM4NUM4\""] <- "weakNUM4NUM4"
colnames(de)[colnames(de) =="exly.rawSamples.\"strong\"\"NUM4SOME\""] <- "strongNUM4SOME"
colnames(de)[colnames(de) =="exly.rawSamples.\"weak\"\"NUM4SOME\""] <- "weakNUM4SOME"
colnames(de)[colnames(de) =="exly.rawSamples.\"strong\"\"SOMENUM4\""] <- "strongSOMENUM4"
colnames(de)[colnames(de) =="exly.rawSamples.\"weak\"\"SOMENUM4\""] <- "weakSOMENUM4"
colnames(de)[colnames(de) =="exly.rawSamples.\"strong\"\"SOMESOME\""] <- "strongSOMESOME"
colnames(de)[colnames(de) =="exly.rawSamples.\"weak\"\"SOMESOME\""] <- "weakSOMESOME"


strongNUM4NUM4Counts <- sum(dd$strongNUM4NUM4, na.rm=TRUE)
weakNUM4NUM4Counts <- sum(dd$weakNUM4NUM4, na.rm=TRUE)
strongNUM4SOMECounts <- sum(dd$strongNUM4SOME, na.rm=TRUE)
weakNUM4SOMECounts <- sum(dd$weakNUM4SOME, na.rm=TRUE)
strongSOMENUM4Counts <- sum(dd$strongSOMENUM4, na.rm=TRUE)
weakSOMENUM4Counts <- sum(dd$weakSOMENUM4, na.rm=TRUE)
strongSOMESOMECounts <- sum(dd$strongSOMESOME, na.rm=TRUE)
weakSOMESOMECounts <- sum(dd$weakSOMESOME, na.rm=TRUE)

strongNUM4NUM4Samples <- sum(de$strongNUM4NUM4, na.rm=TRUE)
weakNUM4NUM4Samples <- sum(de$weakNUM4NUM4, na.rm=TRUE)
strongNUM4SOMESamples <- sum(de$strongNUM4SOME, na.rm=TRUE)
weakNUM4SOMESamples <- sum(de$weakNUM4SOME, na.rm=TRUE)
strongSOMENUM4Samples <- sum(de$strongSOMENUM4, na.rm=TRUE)
weakSOMENUM4Samples <- sum(de$weakSOMENUM4, na.rm=TRUE)
strongSOMESOMESamples <- sum(de$strongSOMESOME, na.rm=TRUE)
weakSOMESOMESamples <- sum(de$weakSOMESOME, na.rm=TRUE)

strongNUM4NUM4Mean <- mean(dd$strongNUM4NUM4, na.rm=TRUE)
weakNUM4NUM4Mean <- mean(dd$weakNUM4NUM4, na.rm=TRUE)
strongNUM4SOMEMean <- mean(dd$strongNUM4SOME, na.rm=TRUE)
weakNUM4SOMEMean <- mean(dd$weakNUM4SOME, na.rm=TRUE)
strongSOMENUM4Mean <- mean(dd$strongSOMENUM4, na.rm=TRUE)
weakSOMENUM4Mean <- mean(dd$weakSOMENUM4, na.rm=TRUE)
strongSOMESOMEMean <- mean(dd$strongSOMESOME, na.rm=TRUE)
weakSOMESOMEMean <- mean(dd$weakSOMESOME, na.rm=TRUE)

strongNUM4NUM4SD <- sd(dd$strongNUM4NUM4, na.rm=TRUE)
weakNUM4NUM4SD <- sd(dd$weakNUM4NUM4, na.rm=TRUE)
strongNUM4SOMESD <- sd(dd$strongNUM4SOME, na.rm=TRUE)
weakNUM4SOMESD <- sd(dd$weakNUM4SOME, na.rm=TRUE)
strongSOMENUM4SD <- sd(dd$strongSOMENUM4, na.rm=TRUE)
weakSOMENUM4SD <- sd(dd$weakSOMENUM4, na.rm=TRUE)
strongSOMESOMESD <- sd(dd$strongSOMESOME, na.rm=TRUE)
weakSOMESOMESD <- sd(dd$weakSOMESOME, na.rm=TRUE)

strongNUM4NUM4SE <- strongNUM4NUM4SD/sqrt(length(dd$workerid))
weakNUM4NUM4SE <- weakNUM4NUM4SD/sqrt(length(dd$workerid))
strongNUM4SOMESE <- strongNUM4SOMESD/sqrt(length(dd$workerid))
weakNUM4SOMESE <- weakNUM4SOMESD/sqrt(length(dd$workerid))
strongSOMENUM4SE <- strongSOMENUM4SD/sqrt(length(dd$workerid))
weakSOMENUM4SE <- weakSOMENUM4SD/sqrt(length(dd$workerid))
strongSOMESOMESE <- strongSOMESOMESD/sqrt(length(dd$workerid))
weakSOMESOMESE <- weakSOMESOMESD/sqrt(length(dd$workerid))

CI <- 1.161

strongNUM4NUM4MeanPlusSE <- (strongNUM4NUM4Mean + (CI * strongNUM4NUM4SE))
weakNUM4NUM4MeanPlusSE <- (weakNUM4NUM4Mean + (CI * weakNUM4NUM4SE))
strongNUM4SOMEMeanPlusSE <- (strongNUM4SOMEMean + (CI * strongNUM4SOMESE))
weakNUM4SOMEMeanPlusSE <- (weakNUM4SOMEMean + (CI * weakNUM4SOMESE))
strongSOMENUM4MeanPlusSE <- (strongSOMENUM4Mean + (CI * strongSOMENUM4SE))
weakSOMENUM4MeanPlusSE <- (weakSOMENUM4Mean + (CI * weakSOMENUM4SE))
strongSOMESOMEMeanPlusSE <- (strongSOMESOMEMean + (CI * strongSOMESOMESE))
weakSOMESOMEMeanPlusSE <- (weakSOMESOMEMean + (CI * weakSOMESOMESE))

strongNUM4NUM4MeanMinusSE <- (strongNUM4NUM4Mean - (CI * strongNUM4NUM4SE))
weakNUM4NUM4MeanMinusSE <- (weakNUM4NUM4Mean - (CI * weakNUM4NUM4SE))
strongNUM4SOMEMeanMinusSE <- (strongNUM4SOMEMean - (CI * strongNUM4SOMESE))
weakNUM4SOMEMeanMinusSE <- (weakNUM4SOMEMean - (CI * weakNUM4SOMESE))
strongSOMENUM4MeanMinusSE <- (strongSOMENUM4Mean - (CI * strongSOMENUM4SE))
weakSOMENUM4MeanMinusSE <- (weakSOMENUM4Mean - (CI * weakSOMENUM4SE))
strongSOMESOMEMeanMinusSE <- (strongSOMESOMEMean - (CI * strongSOMESOMESE))
weakSOMESOMEMeanMinusSE <- (weakSOMESOMEMean - (CI * weakSOMESOMESE))



strongNUM4NUM4MeanPercentage <- (length(dd$workerid) * strongNUM4NUM4Mean)/strongNUM4NUM4Samples
weakNUM4NUM4MeanPercentage <- (length(dd$workerid) * weakNUM4NUM4Mean)/weakNUM4NUM4Samples
strongNUM4SOMEMeanPercentage <- (length(dd$workerid) * strongNUM4SOMEMean)/strongNUM4SOMESamples
weakNUM4SOMEMeanPercentage <- (length(dd$workerid) * weakNUM4SOMEMean)/weakNUM4SOMESamples
strongSOMENUM4MeanPercentage <- (length(dd$workerid) * strongSOMENUM4Mean)/strongSOMENUM4Samples
weakSOMENUM4MeanPercentage <- (length(dd$workerid) * weakSOMENUM4Mean)/weakSOMENUM4Samples
strongSOMESOMEMeanPercentage <- (length(dd$workerid) * strongSOMESOMEMean)/strongSOMESOMESamples
weakSOMESOMEMeanPercentage <- (length(dd$workerid) * weakSOMESOMEMeanMinusSE)/weakSOMESOMESamples

strongNUM4NUM4MeanPlusSEPercentage <- (length(dd$workerid) * strongNUM4NUM4MeanPlusSE)/strongNUM4NUM4Samples
weakNUM4NUM4MeanPlusSEPercentage <- (length(dd$workerid) * weakNUM4NUM4MeanPlusSE)/weakNUM4NUM4Samples
strongNUM4SOMEMeanPlusSEPercentage <- (length(dd$workerid) * strongNUM4SOMEMeanPlusSE)/strongNUM4SOMESamples
weakNUM4SOMEMeanPlusSEPercentage <- (length(dd$workerid) * weakNUM4SOMEMeanPlusSE)/weakNUM4SOMESamples
strongSOMENUM4MeanPlusSEPercentage <- (length(dd$workerid) * strongSOMENUM4MeanPlusSE)/strongSOMENUM4Samples
weakSOMENUM4MeanPlusSEPercentage <- (length(dd$workerid) * weakSOMENUM4MeanPlusSE)/weakSOMENUM4Samples
strongSOMESOMEMeanPlusSEPercentage <- (length(dd$workerid) * strongSOMESOMEMeanPlusSE)/strongSOMESOMESamples
weakSOMESOMEMeanPlusSEPercentage <- (length(dd$workerid) * weakSOMESOMEMeanPlusSE)/weakSOMESOMESamples

strongNUM4NUM4MeanMinusSEPercentage <- (length(dd$workerid) * strongNUM4NUM4MeanMinusSE)/strongNUM4NUM4Samples
weakNUM4NUM4MeanMinusSEPercentage <- (length(dd$workerid) * weakNUM4NUM4MeanMinusSE)/weakNUM4NUM4Samples
strongNUM4SOMEMeanMinusSEPercentage <- (length(dd$workerid) * strongNUM4SOMEMeanMinusSE)/strongNUM4SOMESamples
weakNUM4SOMEMeanMinusSEPercentage <- (length(dd$workerid) * weakNUM4SOMEMeanMinusSE)/weakNUM4SOMESamples
strongSOMENUM4MeanMinusSEPercentage <- (length(dd$workerid) * strongSOMENUM4MeanMinusSE)/strongSOMENUM4Samples
weakSOMENUM4MeanMinusSEPercentage <- (length(dd$workerid) * weakSOMENUM4MeanMinusSE)/weakSOMENUM4Samples
strongSOMESOMEMeanMinusSEPercentage <- (length(dd$workerid) * strongSOMESOMEMeanMinusSE)/strongSOMESOMESamples
weakSOMESOMEMeanMinusSEPercentage <- (length(dd$workerid) * weakSOMESOMEMeanMinusSE)/weakSOMESOMESamples


primeCategory <- c('strongNUM4NUM4', 'weakNUM4NUM4', 'strongNUM4SOME', 'weakNUM4SOME', 'strongSOMENUM4', 'weakSOMENUM4', 'strongSOMESOME', 'weakSOMESOME')

meanPercent <- c(strongNUM4NUM4MeanPercentage, weakNUM4NUM4MeanPercentage, strongNUM4SOMEMeanPercentage, weakNUM4SOMEMeanPercentage, strongSOMENUM4MeanPercentage, weakSOMENUM4MeanPercentage, strongSOMESOMEMeanPercentage, weakSOMESOMEMeanPercentage)

meanPlusCIPercent <- c(strongNUM4NUM4MeanPlusSEPercentage, weakNUM4NUM4MeanPlusSEPercentage, strongNUM4SOMEMeanPlusSEPercentage, weakNUM4SOMEMeanPlusSEPercentage, strongSOMENUM4MeanPlusSEPercentage, weakSOMENUM4MeanPlusSEPercentage, strongSOMESOMEMeanPlusSEPercentage, weakSOMESOMEMeanPlusSEPercentage)

meanMinusCIPercent <- c(strongNUM4NUM4MeanMinusSEPercentage, weakNUM4NUM4MeanMinusSEPercentage, strongNUM4SOMEMeanMinusSEPercentage, weakNUM4SOMEMeanMinusSEPercentage, strongSOMENUM4MeanMinusSEPercentage, weakSOMENUM4MeanMinusSEPercentage, strongSOMESOMEMeanMinusSEPercentage, weakSOMESOMEMeanMinusSEPercentage)

rawMean <- c(strongNUM4NUM4Mean, weakNUM4NUM4Mean, strongNUM4SOMEMean, weakNUM4SOMEMean, strongSOMENUM4Mean, weakSOMENUM4Mean, strongSOMESOMEMean, weakSOMESOMEMean)

rawSD <- c(strongNUM4NUM4SD, weakNUM4NUM4SD, strongNUM4SOMESD, weakNUM4SOMESD, strongSOMENUM4SD, weakSOMENUM4SD, strongSOMESOMESD, weakSOMESOMESD)

rawSE <- c(strongNUM4NUM4SE, weakNUM4NUM4SE, strongNUM4SOMESE, weakNUM4SOMESE, strongSOMENUM4SE, weakSOMENUM4SE, strongSOMESOMESE, weakSOMESOMESE)

rawMeanPlusCI <- c(strongNUM4NUM4MeanPlusSE, weakNUM4NUM4MeanPlusSE, strongNUM4SOMEMeanPlusSE, weakNUM4SOMEMeanPlusSE, strongSOMENUM4MeanPlusSE, weakSOMENUM4MeanPlusSE, strongSOMESOMEMeanPlusSE, weakSOMESOMEMeanPlusSE)

rawMeanMinusCI <- c(strongNUM4NUM4MeanMinusSE, weakNUM4NUM4MeanMinusSE, strongNUM4SOMEMeanMinusSE, weakNUM4SOMEMeanMinusSE, strongSOMENUM4MeanMinusSE, weakSOMENUM4MeanMinusSE, strongSOMESOMEMeanMinusSE, weakSOMESOMEMeanMinusSE)

bars.data <- data.frame(primeCategory, meanPercent, meanPlusCIPercent, meanMinusCIPercent, rawMean, rawSD,  rawSE, rawMeanPlusCI, rawMeanMinusCI)

bars.data
```


```{r}
p.perc <- ddply(p,.(BetCat, primeStrengthText),summarise,prop = sum(as.numeric(as.character(responseChoice)))/length(responseChoice))
p.perc
```

Here's a graph built in R, but it relies on straightforward proportions of responses, and so isn't really taking into account the relative difference in responses for the prime-category pairings.
Rather than mess around with R visualisation, we proceeded with the calculations above and good, proper, hardworking, LaTeX.

```{r}
ggplot(p.perc, aes(x=factor(BetCat),y=prop, fill=primeStrengthText, label=paste(round(prop*100), "%"))) +
  geom_bar(stat="identity", colour="black", position=position_dodge()) +
  ylab("Proportion Strong responses") +
  xlab("Prime Type") +
  scale_fill_manual(values=c("black", "lightgray"))
```


## Individual plots

An alernative approach would be to generate plots for each category indepndently.
Here's some example code to do this.
But again, it has the shortcomings described above.

```{r}
# psswp = subset(p, trial_type=='response' & BetCat=="SOMESOME")
# summary(psswp)
# psswp.perc <- ddply(psswp,.(primeStrengthText),summarise,prop = sum(as.integer(as.character(responseChoice)))/length(responseChoice))

# ggplot(psswp.perc,aes(x=factor(primeStrengthText),y=psswp.perc,label=paste(round(psswp.perc*100), "%")),fill=primeStrength) +
#   geom_bar(colour="black", stat="identity", position=position_dodge()) +
#   ylab("Proportion Strong responses") +
#   xlab("Prime Type") +
#   scale_fill_manual(values=c("black", "lightgray"))
```

## Combining between category primes and responses

Bott and Chemla combine each direction of cross category trials when illustrating their results.
Here's an easy way to do it.
The idea, basically, is to make a new dataframe with only the results from the relevant trials, then one simply, uses this ddply to combine the results of applying the proportion function to each trial type.

As we're only interested in visualising the data in this case, we'll make things easier by filtering our initial dataset, refined to exlude filler trails and cases where the respondant did not select the 'correct' prime choices, by the two between category prime and response type pairs of interest.
Though, again, the problems noted above mean that we won't use this in our analysis.

```{r}
# summary(rp)
# cc = subset(rp, trial_type=='"response"' & (BetCat=='"NUM4SOME"' | BetCat=='"SOMENUM4"'))
# summary(cc)
# cc.perc <- ddply(cc,.(primeStrengthText),summarise, prop = sum(as.integer(as.character(responseChoice)))/length(responseChoice))
# cc.perc
```


# Splitting the data

Unfortunately, we did not explicity record the order in which the trials were presented to the participants in the experiment.
An unfortunate oversight, as Bott and Chemla play around with splitting the data to test whether there are effects on priming in the first or second half of the trial.
However, there's a somewhat easy fix, as the CSV implicitly contains the order of the trials, following the order of the rows in the CSV.
So, using a quick python script we can add a column for the trial number to the dataset.
We save this to the bottchemla2016Numbered CSV.
Let's load this up, and observe the newely added column 'trialNumber' at the end of each row, summarised by the table below.
Whether or not filler trials should be taken into account is not clear from what Bott and Chemla say.
So, as a design choice we decided not to include these in our counts, to get an even split.
This means all filler trails have the number 0, and counting for response trials starts at 1 and goes to 32.

```{r}
pn = read.csv("../data/bottchemla2016Numbered.csv", quote = "\"")
table(pn$trialNumber)
```

Now we've got our enhanced dataset, let's do the same refinements as before.
First is to clean up some factors, ensure English is a native language, and ensure the participant spent a reasonable amount of time on the task.

```{r}
pn$responseChoice = revalue(pn$responseChoice, c("\"0\""="0", "\"1\""="1"))
pn$pOChoice = revalue(pn$pOChoice, c("\"0\""="0", "\"1\""="1"))
pn$pTChoice = revalue(pn$pTChoice, c("\"0\""="0", "\"1\""="1"))

pn = subset(pn, language!='""' & language!='"Chinese"' & language!='"Russian"' & language!='"Urdu"' & language!='"spanish"')

pn$Answer.time_in_minutes <- gsub("\"", "", pn$Answer.time_in_minutes)
pn$Answer.time_in_minutes <- as.numeric(as.character(pn$Answer.time_in_minutes))

pn = subset(pn, Answer.time_in_minutes >= 3)
```

Now, let's filter the dataset for response trials, and those response trails for which the participant got the prime choices correct.

```{r}
rpn = subset(pn, trial_type=='"response"')
rpn = subset(rpn, correctPChoices=='true')
```

Now we're ready to split the data.
We'll create two datasets:
'rpnFst' and 'rpnSnd' for the first and second halves of the dataset, respectively.

```{r}
rpnFst = subset(rpn, trialNumber <= 16)
rpnSnd = subset(rpn, trialNumber > 16)
# summary(rpnFst)
# summary(rpnSnd)
```

And, make sure we get out categories correct.

```{r}
contrasts(rpn$primeStrengthText) <- contr("sum", base=2)
contrasts(rpn$WithCat) <- contr("sum", base=1)
contrasts(rpnFst$primeStrengthText) <- contr("sum", base=2)
contrasts(rpnFst$WithCat) <- contr("sum", base=1)
contrasts(rpnSnd$primeStrengthText) <- contr("sum", base=2)
contrasts(rpnSnd$WithCat) <- contr("sum", base=1)
```

Now, let's run the basic model on both datasets

```{r}
rpnHlv.model = glmer(responseChoice ~ primeStrengthText*WithCat*half + (1 + primeStrengthText*WithCat*half | workerid), data=rpn, family="binomial")
rpnFst.model = glmer(responseChoice ~ primeStrengthText*WithCat + (1 + primeStrengthText*WithCat | workerid), data=rpnFst, family="binomial")
rpnSnd.model = glmer(responseChoice ~ primeStrengthText*WithCat + (1 + primeStrengthText*WithCat | workerid), data=rpnSnd, family="binomial")
```

Sucess! So let's look at the summaries.

Here's taking into account the split
```{r}
summary(rpnHlv.model)
```

Here's the first half:

```{r}
summary(rpnFst.model)
```

And here's the second half:

```{r}
summary(rpnSnd.model)
```

# Ordering Models

There are two further models we should consider.
These correspond to between category priming, where the prime is taken into account.
These relevant datasets are pretty easy to get using the wrp dataset, and the subset operation.

```{r}

head(brp)

brpNumF <- subset(brp, primeTypeText=='"NUM4"')
brpSome <- subset(brp, primeTypeText=='"SOME"')
```

And to check we've done the right thing.

```{r}
table(brpNumF$primeTypeText, brpNumF$responseTypeText)
table(brpSome$primeTypeText, brpSome$responseTypeText)
# summary(wrpNumF)
# summary(wrpSome)
```

Now we've got the right data, let's fix the factors


```{r}
contrasts(brpNumF$primeStrengthText) <- contr("sum", base=2)
contrasts(brpSome$primeStrengthText) <- contr("sum", base=2)


```



And now let's run the appropriate models.

```{r}
brpNumF.model = glmer(responseChoice ~ primeStrengthText + (1 + primeStrengthText | workerid), data=brpNumF, family="binomial")
brpSome.model = glmer(responseChoice ~ primeStrengthText + (1 + primeStrengthText | workerid), data=brpSome, family="binomial")
```

And, we can see the summary for the number prime:

```{r}
summary(brpNumF.model)
```

And for the some prime:

```{r}
summary(brpSome.model)
```